---
layout:       post
title:        "point"
author:       "AJohn"
header-style: text
catalog:      true
tags:
    - Blog
    - Deep Learning
---

>存放一些重要的point

# 样本选择：
1. 小损失准则（small-loss trick）：将训练损失较小的样本视为干净样本。由于 DNN 倾向于在拟合噪声样本之前先学习简单模式，因此许多研究利用小损失技巧，其中损失较小的样本被视为干净样本。
   - 缺点：需要知道噪声比率，从而确定前百分之多少小损失是干净样本

>优化：使用GMM

2. 深度神经网络的记忆效应：当网络在带有噪声标签的数据上进行训练时，会在过度拟合带有噪声标签的数据之前首先学习更简单的模式。也就是说，它们会首先记住干净标签的训练数据，然后记住噪声标签的训练数据。因此，我们可以在记住噪声样本前终止记忆，选择小损失的例子来更新网络的参数。